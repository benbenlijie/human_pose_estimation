{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, show\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"e4cb1f60-355d-41cb-b309-67b58b0f93cc\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (window._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    window._bokeh_timeout = Date.now() + 5000;\n",
       "    window._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (window.Bokeh !== undefined) {\n",
       "      document.getElementById(\"e4cb1f60-355d-41cb-b309-67b58b0f93cc\").textContent = \"BokehJS successfully loaded.\";\n",
       "    } else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"e4cb1f60-355d-41cb-b309-67b58b0f93cc\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'e4cb1f60-355d-41cb-b309-67b58b0f93cc' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      document.getElementById(\"e4cb1f60-355d-41cb-b309-67b58b0f93cc\").textContent = \"BokehJS is loading...\";\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((window.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!window._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      window._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"e4cb1f60-355d-41cb-b309-67b58b0f93cc\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self, batch_size, image_shape, stack_size=2, module_size=2, channel_size=[32, 64, 128]):\n",
    "        self.batch_size = batch_size\n",
    "        self.image_shape = image_shape\n",
    "        self.stack_size = stack_size\n",
    "        self.module_size = module_size\n",
    "        self.channel_size = channel_size\n",
    "        self.alpha = 0.2\n",
    "        #with tf.variable_scope(\"generator\"):\n",
    "        self.inputs = tf.placeholder(tf.float32, shape=[None, *image_shape], name=\"inputs\")\n",
    "    \n",
    "    def leaky_relu(self, inputs):\n",
    "        return tf.maximum(inputs, inputs * self.alpha)\n",
    "    \n",
    "    def kinit(size, dtype, partition_info):\n",
    "        return tf.random_normal(size, stddev=0.02)\n",
    "\n",
    "    def build_module(self, inputs, name, channels=[32, 64, 128]):\n",
    "        with tf.variable_scope(name + \"_module\"):\n",
    "            with slim.arg_scope([slim.conv2d, slim.conv2d_transpose], padding=\"SAME\", kernel_size=3, stride=2, activation_fn=self.leaky_relu, \n",
    "                          weights_initializer=tf.truncated_normal_initializer(stddev=0.01)):\n",
    "                return self.conv_module(inputs, channels)\n",
    "\n",
    "    def conv_module(self, inputs, channels):\n",
    "        conv_layer = slim.conv2d(inputs, channels[0])\n",
    "        if len(channels) > 1:\n",
    "            #recursive\n",
    "            inner_layer = self.conv_module(conv_layer, channels[1:])\n",
    "            concat_layer = tf.concat([conv_layer, inner_layer], axis=-1)\n",
    "        else:\n",
    "            concat_layer = conv_layer\n",
    "        deconv_layer = slim.conv2d_transpose(concat_layer, channels[0])\n",
    "        return deconv_layer\n",
    "    \n",
    "    def build_stack(self, inputs, training=True):\n",
    "        with slim.arg_scope([slim.conv2d], kernel_size=5, stride=1, padding=\"SAME\",\n",
    "                       activation_fn=self.leaky_relu, weights_initializer=tf.truncated_normal_initializer(stddev=0.02)):\n",
    "            conv_layer = slim.conv2d(inputs, num_outputs=32, )\n",
    "            pose_heatmap = self.build_module(conv_layer, \"pose\", self.channel_size)\n",
    "            concat_layer = tf.concat([pose_heatmap, conv_layer], axis=-1)\n",
    "            occlusion_heatmap = self.build_module(concat_layer, \"occlusion\", self.channel_size)\n",
    "            pose_heatmap = slim.conv2d(pose_heatmap, 1)\n",
    "            occlusion_heatmap = slim.conv2d(occlusion_heatmap, 1)\n",
    "            pose_heatmap = tf.nn.tanh(pose_heatmap)\n",
    "            occlusion_heatmap = tf.nn.tanh(occlusion_heatmap)\n",
    "            output = tf.concat([conv_layer, pose_heatmap, occlusion_heatmap], axis=-1, name=\"stack_output\")\n",
    "            return output, pose_heatmap, occlusion_heatmap\n",
    "    \n",
    "    def build(self, training=True):\n",
    "        module_input = self.inputs\n",
    "        for i in range(self.module_size):\n",
    "            with tf.variable_scope(\"generator_\"+str(i), reuse=not training):\n",
    "                module_output, pose_heatmap, occlusion_heatmap = self.build_stack(module_input, training)\n",
    "                module_input = module_output\n",
    "        self.pose_heatmap = pose_heatmap\n",
    "        self.occlusion_heatmap = occlusion_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_img(fileName, new_size=[512, 512]):\n",
    "    filePattern = \"./sample_img/{}.jpg\"\n",
    "    fileSource = filePattern.format(fileName)\n",
    "    avatar = Image.open(fileSource)\n",
    "    return avatar.resize(new_size, Image.ANTIALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img = \"4e497571583a077564df4b547e40408fd9915ecc\"\n",
    "\n",
    "tmp_img = resize_img(test_img)\n",
    "tmp_np_img = np.array(tmp_img)\n",
    "tmp_np_img.shape\n",
    "tmp_img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "save_path = \"./model_res/keypoint_annotation.pkl\"\n",
    "\n",
    "with open(save_path, mode=\"rb\") as f:\n",
    "    kp_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self, image_folder, kp_data, batch_size=32, image_size=[512, 512]):\n",
    "        self.image_folder = image_folder\n",
    "        self.file_pattern = image_folder+\"/{}.jpg\"\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.image_names = [os.path.splitext(file)[0] for file in os.listdir(image_folder)]\n",
    "        self.kp_data = kp_data\n",
    "    \n",
    "    def get_batch(self):\n",
    "        if self.image_names == None:\n",
    "            return None\n",
    "        total_amount = len(self.image_names)\n",
    "        batch_count = total_amount // self.batch_size\n",
    "        for i in range(0, batch_count * self.batch_size, self.batch_size):\n",
    "            the_batch = self.image_names[i:i+self.batch_size]\n",
    "            heatmaps = np.array(list(map(self.make_heatmap, the_batch)))\n",
    "            yield np.array(list(map(self.preprocess, the_batch))), heatmaps[:, 0], heatmaps[:, 1]\n",
    "        pass\n",
    "    \n",
    "    def preprocess(self, image_name):\n",
    "        file_path = self.file_pattern.format(image_name)\n",
    "        avatar = Image.open(file_path)\n",
    "\n",
    "        resized_image = avatar.resize(self.image_size, Image.ANTIALIAS)\n",
    "        return np.array(resized_image) / 255.\n",
    "        \n",
    "    \n",
    "    def get_kp_data(self, image_name):\n",
    "        human_kp_data = self.kp_data[image_name]['keypoint_annotations']['human1']\n",
    "        return human_kp_data\n",
    "    \n",
    "    def make_heatmap(self, image_name):\n",
    "        file_path = self.file_pattern.format(image_name)\n",
    "        avatar = Image.open(file_path)\n",
    "        width, height = avatar.size\n",
    "        kp_data = self.get_kp_data(image_name)\n",
    "        heatmap = np.ones((self.image_size[1], self.image_size[0], 1)) * -1\n",
    "        occlusion_heatmap = np.ones((self.image_size[1], self.image_size[0], 1)) * -1\n",
    "        for i in range(0, len(kp_data), 3):\n",
    "            ori_x, ori_y, status = kp_data[i:i+3]\n",
    "            new_x = int(ori_x * (self.image_size[0] * 1. / width))\n",
    "            new_y = int(ori_y * (self.image_size[1] * 1. / height))\n",
    "            if status == 1:\n",
    "                heatmap[new_y, new_x, 0] = 1\n",
    "            elif status == 2:\n",
    "                occlusion_heatmap[new_y, new_x, 0] = 1\n",
    "        return heatmap, occlusion_heatmap\n",
    "    \n",
    "    def DrawImage(self, image_name):\n",
    "        file_path = self.file_pattern.format(image_name)\n",
    "        avatar = Image.open(file_path)\n",
    "        print(avatar.size)\n",
    "        drawAvatar = ImageDraw.Draw(avatar)\n",
    "        annotation_data = self.kp_data[image_name]\n",
    "        draw_human_boundary(drawAvatar, annotation_data)\n",
    "        draw_keypoint(drawAvatar, annotation_data)\n",
    "        del drawAvatar\n",
    "        return avatar\n",
    "\n",
    "    def draw_human_boundary(drawAvatar, annotation_data):\n",
    "        if 'human_annotations' in annotation_data:\n",
    "            human_data_set = annotation_data['human_annotations']\n",
    "            for humman_data in human_data_set:\n",
    "                drawAvatar.rectangle(human_data_set[humman_data], outline=(255, 10, 0))\n",
    "\n",
    "    def draw_keypoint(drawAvatar, annotation_data):\n",
    "        if \"keypoint_annotations\" in annotation_data:\n",
    "            keypoint_data_set = annotation_data[\"keypoint_annotations\"]\n",
    "            for keypoint_key in keypoint_data_set:\n",
    "                points = keypoint_data_set[keypoint_key]\n",
    "                for i in range(0, len(points), 3):\n",
    "                    if points[i+2] == 1:\n",
    "                        fill = (10, 255, 10)\n",
    "                    elif points[i+2] == 2:\n",
    "                        fill = (255, 10, 10)\n",
    "                    else:\n",
    "                        fill = None\n",
    "                    if fill is not None:\n",
    "                        arc_points = [points[i] - 3, points[i+1] - 3, points[i] + 3, points[i+1] + 3]\n",
    "                        drawAvatar.arc(arc_points, start=0, end=360, fill=fill)\n",
    "                        drawAvatar.text((points[i]+10, points[i+1]), \"{}\".format((i // 3)+1), fill=fill)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'preprocessor.get_kp_data(test_img)\\n\\nheatmap, occlusion_heatmap = preprocessor.make_heatmap(test_img)\\n\\nImage.fromarray(((heatmap + 1) * 255).squeeze().astype(np.int32))\\n\\n\\nheatmap[((heatmap + 1) * 255).squeeze().astype(np.int32).nonzero()]\\n\\ntest_img = \"1b75657cd05ff89859bf800a30c0691c776dd880\"\\npreprocessor.DrawImage(test_img)\\n\\n\\na, b, c = preprocessor.image_names[0:3]\\nprint(a, b, c)\\n\\nlen(preprocessor.image_names)\\nlist(map(lambda x: x[-1], preprocessor.image_names))\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"preprocessor.get_kp_data(test_img)\n",
    "\n",
    "heatmap, occlusion_heatmap = preprocessor.make_heatmap(test_img)\n",
    "\n",
    "Image.fromarray(((heatmap + 1) * 255).squeeze().astype(np.int32))\n",
    "\n",
    "\n",
    "heatmap[((heatmap + 1) * 255).squeeze().astype(np.int32).nonzero()]\n",
    "\n",
    "test_img = \"1b75657cd05ff89859bf800a30c0691c776dd880\"\n",
    "preprocessor.DrawImage(test_img)\n",
    "\n",
    "\n",
    "a, b, c = preprocessor.image_names[0:3]\n",
    "print(a, b, c)\n",
    "\n",
    "len(preprocessor.image_names)\n",
    "list(map(lambda x: x[-1], preprocessor.image_names))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Discriminator:\n",
    "    def __init__(self, batch_size, image_shape, output_size=14, channel_size=[32, 64, 128]):\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.channel_size = channel_size\n",
    "        self.output_size = output_size\n",
    "        self.alpha = 0.2\n",
    "\n",
    "    def leaky_relu(self, inputs):\n",
    "        return tf.maximum(inputs, inputs * self.alpha)\n",
    "    \n",
    "    def kinit(size, dtype, partition_info):\n",
    "        return tf.random_normal(size, stddev=0.02)\n",
    "    \n",
    "    def build_module(self, inputs, name, channels=[32, 64, 128]):\n",
    "        with tf.variable_scope(name + \"_module\"):\n",
    "            with slim.arg_scope([slim.conv2d, slim.conv2d_transpose], padding=\"SAME\", kernel_size=3, stride=2, activation_fn=self.leaky_relu, \n",
    "                          weights_initializer=tf.truncated_normal_initializer(stddev=0.01)):\n",
    "                return self.conv_module(inputs, channels)\n",
    "\n",
    "    def conv_module(self, inputs, channels):\n",
    "        conv_layer = slim.conv2d(inputs, channels[0])\n",
    "        if len(channels) > 1:\n",
    "            #recursive\n",
    "            inner_layer = self.conv_module(conv_layer, channels[1:])\n",
    "            concat_layer = tf.concat([conv_layer, inner_layer], axis=-1)\n",
    "        else:\n",
    "            concat_layer = conv_layer\n",
    "        deconv_layer = slim.conv2d_transpose(concat_layer, channels[0])\n",
    "        return deconv_layer\n",
    "    \n",
    "    def build(self, inputs, name, reuse=False):\n",
    "        with tf.variable_scope(\"discriminator_\"+name, reuse=reuse):\n",
    "            conv_output = self.build_module(inputs, name, self.channel_size)\n",
    "            flatten_layer = slim.flatten(conv_output)\n",
    "            self.digits = slim.fully_connected(flatten_layer, self.output_size, activation_fn=None, \n",
    "                                 weights_initializer=tf.random_normal_initializer(stddev=0.01))\n",
    "            \n",
    "            self.outputs = tf.nn.sigmoid(self.digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size= 2\n",
    "image_size = [512, 512, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "#build generator model\n",
    "generator = Generator(batch_size, image_size)\n",
    "generator.build(True)\n",
    "#get generator output\n",
    "pose_heatmap = generator.pose_heatmap\n",
    "occlusion_heatmap = generator.occlusion_heatmap\n",
    "\n",
    "#create discriminator\n",
    "pose_discriminator = Discriminator(batch_size, image_size)\n",
    "conf_discriminator = Discriminator(batch_size, image_size)\n",
    "\n",
    "#true heatmap input\n",
    "pose_pl = tf.placeholder(tf.float32, [None, image_size[0], image_size[1], 1], name=\"pose_true_heatmap\")\n",
    "occlusion_pl = tf.placeholder(tf.float32, [None, image_size[0], image_size[1], 1], name=\"occlusion_true_heatmap\")\n",
    "\n",
    "#discriminator for true heatmap\n",
    "pose_true_inputs = tf.concat([generator.inputs, pose_pl, occlusion_pl], axis=-1,\n",
    "                            name=\"pose_true_inputs\")\n",
    "conf_true_inputs = tf.concat([pose_pl, occlusion_pl], axis=-1,\n",
    "                            name=\"conf_true_inputs\")\n",
    "pose_discriminator.build(pose_true_inputs, \"pose\")\n",
    "conf_discriminator.build(conf_true_inputs, \"confidence\")\n",
    "pose_true_output = [pose_discriminator.digits, pose_discriminator.outputs]\n",
    "conf_true_output = [conf_discriminator.digits, conf_discriminator.outputs]\n",
    "\n",
    "#discriminator for fake heatmap\n",
    "pose_fake_inputs = tf.concat([generator.inputs, generator.pose_heatmap, generator.occlusion_heatmap], axis=-1,\n",
    "                            name=\"pose_fake_inputs\")\n",
    "conf_fake_inputs = tf.concat([generator.pose_heatmap, generator.occlusion_heatmap], axis=-1,\n",
    "                            name=\"conf_fake_inputs\")\n",
    "pose_discriminator.build(pose_fake_inputs, \"pose\", True)\n",
    "conf_discriminator.build(conf_fake_inputs, \"confidence\", True)\n",
    "pose_fake_output = [pose_discriminator.digits, pose_discriminator.outputs]\n",
    "conf_fake_output = [conf_discriminator.digits, conf_discriminator.outputs]\n",
    "\n",
    "variables = tf.trainable_variables()\n",
    "slim.summarize_tensors(variables)\n",
    "merged = tf.summary.merge_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lam = 10\n",
    "pose_eps = tf.random_uniform([image_size[0], image_size[1], 1], minval=0., maxval=1.)\n",
    "pose_inter = pose_eps * pose_pl + (1. - pose_eps) * generator.pose_heatmap\n",
    "occlusion_eps = tf.random_uniform([image_size[0], image_size[1], 1], minval=0., maxval=1.)\n",
    "occlusion_inter = occlusion_eps * occlusion_pl + (1. - occlusion_eps) * generator.occlusion_heatmap\n",
    "\n",
    "pose_inter_input = tf.concat([generator.inputs, pose_inter, occlusion_inter], axis=-1,\n",
    "                            name=\"pose_fake_inputs\")\n",
    "pose_discriminator.build(pose_inter_input, \"pose\", True)\n",
    "pose_grad = tf.gradients(pose_discriminator.digits, [pose_inter_input])[0]\n",
    "pose_grad_norm = tf.sqrt(tf.reduce_sum((pose_grad)**2, axis=1))\n",
    "pose_grad_pen = lam * tf.reduce_mean((pose_grad_norm - 1)**2)\n",
    "D_pose_loss = tf.reduce_mean(pose_fake_output[0]) - tf.reduce_mean(pose_true_output[0]) + pose_grad_pen\n",
    "\n",
    "\n",
    "conf_inter_input = tf.concat([pose_inter, occlusion_inter], axis=-1,\n",
    "                            name=\"conf_fake_inputs\")\n",
    "conf_discriminator.build(conf_inter_input, \"confidence\", True)\n",
    "conf_grad = tf.gradients(conf_discriminator.digits, [conf_inter_input])[0]\n",
    "conf_grad_norm = tf.sqrt(tf.reduce_sum((conf_grad)**2, axis=1))\n",
    "conf_grad_pen = lam * tf.reduce_mean((conf_grad_norm - 1)**2)\n",
    "D_conf_loss = tf.reduce_mean(conf_fake_output[0]) - tf.reduce_mean(conf_true_output[0]) + conf_grad_pen\n",
    "\n",
    "G_loss = -tf.reduce_mean(pose_fake_output[0]) - tf.reduce_mean(conf_fake_output[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_variables = tf.trainable_variables()\n",
    "generate_vars = [var for var in all_variables if var.name.startswith(\"generator\")]\n",
    "pose_d_vars = [var for var in all_variables if var.name.startswith(\"discriminator_pose\")]\n",
    "conf_d_vars = [var for var in all_variables if var.name.startswith(\"discriminator_conf\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'discriminator_pose/pose_module/Conv/weights:0' shape=(3, 3, 5, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'discriminator_pose/pose_module/Conv/biases:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'discriminator_pose/pose_module/Conv_1/weights:0' shape=(3, 3, 32, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'discriminator_pose/pose_module/Conv_1/biases:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'discriminator_pose/pose_module/Conv_2/weights:0' shape=(3, 3, 64, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'discriminator_pose/pose_module/Conv_2/biases:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'discriminator_pose/pose_module/Conv2d_transpose/weights:0' shape=(3, 3, 128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'discriminator_pose/pose_module/Conv2d_transpose/biases:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'discriminator_pose/pose_module/Conv2d_transpose_1/weights:0' shape=(3, 3, 64, 192) dtype=float32_ref>,\n",
       " <tf.Variable 'discriminator_pose/pose_module/Conv2d_transpose_1/biases:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'discriminator_pose/pose_module/Conv2d_transpose_2/weights:0' shape=(3, 3, 32, 96) dtype=float32_ref>,\n",
       " <tf.Variable 'discriminator_pose/pose_module/Conv2d_transpose_2/biases:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'discriminator_pose/fully_connected/weights:0' shape=(8388608, 14) dtype=float32_ref>,\n",
       " <tf.Variable 'discriminator_pose/fully_connected/biases:0' shape=(14,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pose_d_vars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "beta1 = 0.2\n",
    "preprocessor = Preprocessor(\"sample_img\", kp_data, batch_size=batch_size)\n",
    "epoches = 50\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_pose_solver = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(D_pose_loss, var_list=pose_d_vars)\n",
    "D_conf_solver = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(D_conf_loss, var_list=conf_d_vars)\n",
    "G_solver = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(G_loss, var_list=generate_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pose loss:9.910619735717773 conf loss:9.909833908081055 generate loss:-0.9241063594818115 spend 140.21509981155396 sec\n",
      "pose loss:1.341780662536621 conf loss:2.6288623809814453 generate loss:-2.733858346939087 spend 109.09760022163391 sec\n",
      "pose loss:-48.272586822509766 conf loss:-38.166419982910156 generate loss:21.18093490600586 spend 97.32292056083679 sec\n",
      "pose loss:-219.35037231445312 conf loss:-178.5438232421875 generate loss:141.35708618164062 spend 108.5876157283783 sec\n",
      "pose loss:-712.5606689453125 conf loss:-532.9873657226562 generate loss:14.20733642578125 spend 107.81012225151062 sec\n",
      "pose loss:-1123.3970947265625 conf loss:-846.3607788085938 generate loss:-14515.1953125 spend 102.03330564498901 sec\n",
      "pose loss:422.00494384765625 conf loss:462.3708801269531 generate loss:-9265.98046875 spend 83.09481430053711 sec\n",
      "pose loss:47.05528259277344 conf loss:26.80214500427246 generate loss:-6425.888671875 spend 74.54572343826294 sec\n",
      "pose loss:17.468074798583984 conf loss:9.030993461608887 generate loss:-5220.2197265625 spend 74.26974678039551 sec\n",
      "pose loss:9.306877136230469 conf loss:5.691168785095215 generate loss:-4701.41455078125 spend 73.08383083343506 sec\n",
      "pose loss:6.811646938323975 conf loss:4.505167007446289 generate loss:-4038.478515625 spend 69.92577719688416 sec\n",
      "pose loss:4.28117561340332 conf loss:3.524388313293457 generate loss:-3946.974365234375 spend 77.17159605026245 sec\n",
      "pose loss:3.4155848026275635 conf loss:3.0750198364257812 generate loss:-3266.817138671875 spend 74.13260531425476 sec\n",
      "pose loss:2.495281219482422 conf loss:2.4897871017456055 generate loss:-3051.681640625 spend 75.04814195632935 sec\n",
      "pose loss:1.3435633182525635 conf loss:1.340346336364746 generate loss:-2933.910888671875 spend 71.59176874160767 sec\n",
      "pose loss:0.03647589683532715 conf loss:-0.16730904579162598 generate loss:-2965.37890625 spend 74.51697540283203 sec\n",
      "pose loss:1.7521398067474365 conf loss:1.557815432548523 generate loss:-2568.2587890625 spend 76.33565616607666 sec\n",
      "pose loss:1.451782464981079 conf loss:1.178231954574585 generate loss:-2526.484375 spend 77.072500705719 sec\n",
      "pose loss:1.1068583726882935 conf loss:0.8194375038146973 generate loss:-2388.96435546875 spend 77.68532156944275 sec\n",
      "pose loss:1.3387384414672852 conf loss:0.8047396540641785 generate loss:-2237.09033203125 spend 72.97477316856384 sec\n",
      "pose loss:1.1598565578460693 conf loss:0.7180966734886169 generate loss:-2208.751953125 spend 75.05408906936646 sec\n",
      "pose loss:-0.43161821365356445 conf loss:-1.107387661933899 generate loss:-2631.4375 spend 75.23840498924255 sec\n",
      "pose loss:1.2141741514205933 conf loss:0.7130451202392578 generate loss:-2144.0830078125 spend 74.08163642883301 sec\n",
      "pose loss:0.13851261138916016 conf loss:-0.37618815898895264 generate loss:-2437.01318359375 spend 74.15683722496033 sec\n",
      "pose loss:-3.3139774799346924 conf loss:-3.3255245685577393 generate loss:-2531.140380859375 spend 77.65988874435425 sec\n",
      "pose loss:-3.5769925117492676 conf loss:-3.352417469024658 generate loss:-2727.3828125 spend 73.07786440849304 sec\n",
      "pose loss:1.346862554550171 conf loss:0.5784018039703369 generate loss:-2327.623779296875 spend 72.89789056777954 sec\n",
      "pose loss:0.8705083131790161 conf loss:0.42045921087265015 generate loss:-2158.65234375 spend 73.70627522468567 sec\n",
      "pose loss:0.7838176488876343 conf loss:0.430478036403656 generate loss:-1844.0498046875 spend 71.75886559486389 sec\n",
      "pose loss:0.7445239424705505 conf loss:0.400063693523407 generate loss:-1957.69580078125 spend 73.44909071922302 sec\n",
      "pose loss:0.7789196968078613 conf loss:0.4066920280456543 generate loss:-1653.020263671875 spend 74.2726001739502 sec\n",
      "pose loss:0.6674482822418213 conf loss:0.2823987901210785 generate loss:-2149.74462890625 spend 72.50353050231934 sec\n",
      "pose loss:0.6804967522621155 conf loss:0.33579760789871216 generate loss:-1566.1407470703125 spend 73.07674479484558 sec\n",
      "pose loss:0.613586962223053 conf loss:0.29198870062828064 generate loss:-1646.731689453125 spend 70.35403108596802 sec\n",
      "pose loss:0.3544914722442627 conf loss:0.030474305152893066 generate loss:-1813.1243896484375 spend 70.91029834747314 sec\n",
      "pose loss:0.026553869247436523 conf loss:-0.296459823846817 generate loss:-2073.408203125 spend 72.24246001243591 sec\n",
      "pose loss:0.5831735134124756 conf loss:0.25412964820861816 generate loss:-1598.32080078125 spend 71.57690238952637 sec\n",
      "pose loss:0.42100948095321655 conf loss:0.18077370524406433 generate loss:-1704.068359375 spend 79.14897274971008 sec\n",
      "pose loss:0.35820671916007996 conf loss:0.13212037086486816 generate loss:-1649.7509765625 spend 76.61922574043274 sec\n",
      "pose loss:0.4679264426231384 conf loss:0.15594612061977386 generate loss:-1601.42138671875 spend 75.2685112953186 sec\n",
      "pose loss:0.38152003288269043 conf loss:0.15537267923355103 generate loss:-1645.23779296875 spend 90.43766212463379 sec\n",
      "pose loss:-0.01902306079864502 conf loss:-0.33703818917274475 generate loss:-2196.2236328125 spend 97.13629651069641 sec\n",
      "pose loss:0.49321067333221436 conf loss:0.1827988624572754 generate loss:-1584.7646484375 spend 77.84092211723328 sec\n",
      "pose loss:-0.0020394325256347656 conf loss:-0.28605982661247253 generate loss:-2067.49169921875 spend 78.08228707313538 sec\n",
      "pose loss:-1.0632565021514893 conf loss:-1.157792091369629 generate loss:-2067.45458984375 spend 76.81166958808899 sec\n",
      "pose loss:-1.5101361274719238 conf loss:-1.5566519498825073 generate loss:-2242.13525390625 spend 86.30476689338684 sec\n",
      "pose loss:0.4182478189468384 conf loss:0.14745160937309265 generate loss:-1842.026123046875 spend 77.38962054252625 sec\n",
      "pose loss:0.19731424748897552 conf loss:0.044661201536655426 generate loss:-1821.6192626953125 spend 74.14945983886719 sec\n",
      "pose loss:0.2515794634819031 conf loss:0.09256202727556229 generate loss:-1642.92333984375 spend 73.63111305236816 sec\n",
      "pose loss:0.24839234352111816 conf loss:0.09086194634437561 generate loss:-1845.6044921875 spend 73.20883178710938 sec\n",
      "pose loss:0.323598712682724 conf loss:0.11865147203207016 generate loss:-1499.211181640625 spend 70.92030668258667 sec\n",
      "pose loss:0.18979370594024658 conf loss:0.043621279299259186 generate loss:-2037.892578125 spend 72.61751127243042 sec\n",
      "pose loss:0.24410784244537354 conf loss:0.0961778536438942 generate loss:-1459.90771484375 spend 71.9599997997284 sec\n",
      "pose loss:0.21841312944889069 conf loss:0.0712130218744278 generate loss:-1569.356201171875 spend 72.13236594200134 sec\n",
      "pose loss:0.03424125909805298 conf loss:-0.10857535153627396 generate loss:-1733.169189453125 spend 72.11215734481812 sec\n",
      "pose loss:-0.20624417066574097 conf loss:-0.3511480987071991 generate loss:-2010.365478515625 spend 71.67239832878113 sec\n",
      "pose loss:0.21343892812728882 conf loss:0.0831318199634552 generate loss:-1521.1187744140625 spend 70.92450404167175 sec\n",
      "pose loss:0.127547949552536 conf loss:0.0409170463681221 generate loss:-1658.21484375 spend 72.1261100769043 sec\n",
      "pose loss:0.10431244969367981 conf loss:0.02416139654815197 generate loss:-1602.8665771484375 spend 75.64854192733765 sec\n",
      "pose loss:0.17227941751480103 conf loss:0.04878575727343559 generate loss:-1596.19189453125 spend 72.90162706375122 sec\n",
      "pose loss:0.15258900821208954 conf loss:0.06005758047103882 generate loss:-1607.2139892578125 spend 71.4326798915863 sec\n",
      "pose loss:-0.1088341474533081 conf loss:-0.2648335099220276 generate loss:-2152.547119140625 spend 78.71052575111389 sec\n",
      "pose loss:0.2338026911020279 conf loss:0.09186002612113953 generate loss:-1494.2769775390625 spend 77.7078332901001 sec\n",
      "pose loss:-0.08822444081306458 conf loss:-0.24598845839500427 generate loss:-2048.6083984375 spend 77.30976414680481 sec\n",
      "pose loss:-0.8491005897521973 conf loss:-0.8564067482948303 generate loss:-2028.42822265625 spend 78.60802292823792 sec\n",
      "pose loss:-0.9887796640396118 conf loss:-0.999964714050293 generate loss:-2146.74462890625 spend 72.83973670005798 sec\n",
      "pose loss:0.18748389184474945 conf loss:0.0920196920633316 generate loss:-1736.078369140625 spend 72.29808735847473 sec\n",
      "pose loss:0.050498880445957184 conf loss:0.004893114790320396 generate loss:-1805.3115234375 spend 69.38947367668152 sec\n",
      "pose loss:0.10913793742656708 conf loss:0.059381965547800064 generate loss:-1651.4605712890625 spend 72.2882182598114 sec\n",
      "pose loss:0.10518898069858551 conf loss:0.058842744678258896 generate loss:-1824.81982421875 spend 71.65681910514832 sec\n",
      "pose loss:0.1590578556060791 conf loss:0.0841730386018753 generate loss:-1484.263916015625 spend 71.13163232803345 sec\n",
      "pose loss:0.07573108375072479 conf loss:0.028064008802175522 generate loss:-2010.888427734375 spend 76.54407453536987 sec\n",
      "pose loss:0.11715860664844513 conf loss:0.0692964419722557 generate loss:-1464.9833984375 spend 74.23867130279541 sec\n",
      "pose loss:0.09631293267011642 conf loss:0.046609312295913696 generate loss:-1568.108154296875 spend 75.8297131061554 sec\n",
      "pose loss:-0.02743189036846161 conf loss:-0.0833861380815506 generate loss:-1722.2056884765625 spend 76.11579537391663 sec\n",
      "pose loss:-0.21398121118545532 conf loss:-0.2718982994556427 generate loss:-1989.16943359375 spend 73.5622124671936 sec\n",
      "pose loss:0.1035333126783371 conf loss:0.06125880777835846 generate loss:-1513.9334716796875 spend 72.30529499053955 sec\n",
      "pose loss:0.05521680414676666 conf loss:0.02889222279191017 generate loss:-1659.2474365234375 spend 69.72657513618469 sec\n",
      "pose loss:0.04705541953444481 conf loss:0.02548881620168686 generate loss:-1593.7177734375 spend 73.07675528526306 sec\n",
      "pose loss:0.0984087809920311 conf loss:0.03850822523236275 generate loss:-1610.404541015625 spend 71.16346788406372 sec\n",
      "pose loss:0.09319284558296204 conf loss:0.04857073724269867 generate loss:-1592.037841796875 spend 73.8093192577362 sec\n",
      "pose loss:-0.09380358457565308 conf loss:-0.17827104032039642 generate loss:-2134.92822265625 spend 75.37342834472656 sec\n",
      "pose loss:0.1455998718738556 conf loss:0.07428319752216339 generate loss:-1470.8350830078125 spend 72.48948454856873 sec\n",
      "pose loss:-0.0827578753232956 conf loss:-0.18274126946926117 generate loss:-2059.205810546875 spend 77.99842309951782 sec\n",
      "pose loss:-0.6518378853797913 conf loss:-0.6329363584518433 generate loss:-1995.114501953125 spend 73.48847508430481 sec\n",
      "pose loss:-0.6660411953926086 conf loss:-0.6601226925849915 generate loss:-2083.30615234375 spend 71.30856513977051 sec\n",
      "pose loss:0.10209181904792786 conf loss:0.07591215521097183 generate loss:-1707.5833740234375 spend 72.30026316642761 sec\n",
      "pose loss:0.017251551151275635 conf loss:-0.0023335982114076614 generate loss:-1828.01708984375 spend 72.50836515426636 sec\n",
      "pose loss:0.06856723129749298 conf loss:0.0533374659717083 generate loss:-1655.8626708984375 spend 72.445321559906 sec\n",
      "pose loss:0.06669192016124725 conf loss:0.051160529255867004 generate loss:-1806.66064453125 spend 71.76199436187744 sec\n",
      "pose loss:0.1031414270401001 conf loss:0.0724572092294693 generate loss:-1495.997314453125 spend 75.97184991836548 sec\n",
      "pose loss:0.04317303001880646 conf loss:0.027898933738470078 generate loss:-1991.863525390625 spend 71.87795519828796 sec\n",
      "pose loss:0.08480054885149002 conf loss:0.061701152473688126 generate loss:-1487.11181640625 spend 71.89995980262756 sec\n",
      "pose loss:0.06055141240358353 conf loss:0.03986310586333275 generate loss:-1568.5462646484375 spend 73.01673865318298 sec\n",
      "pose loss:-0.03423824533820152 conf loss:-0.05706877261400223 generate loss:-1717.663818359375 spend 70.89028549194336 sec\n",
      "pose loss:-0.18591508269309998 conf loss:-0.20727109909057617 generate loss:-1979.186279296875 spend 70.22684359550476 sec\n",
      "pose loss:0.06859171390533447 conf loss:0.05353879928588867 generate loss:-1523.283447265625 spend 72.35037922859192 sec\n",
      "pose loss:0.034037381410598755 conf loss:0.026936648413538933 generate loss:-1662.3272705078125 spend 71.99101948738098 sec\n",
      "pose loss:0.034069932997226715 conf loss:0.031078003346920013 generate loss:-1590.6602783203125 spend 77.28871011734009 sec\n",
      "pose loss:0.07506484538316727 conf loss:0.036612510681152344 generate loss:-1629.9017333984375 spend 83.84742736816406 sec\n",
      "pose loss:0.07695455849170685 conf loss:0.04441113770008087 generate loss:-1576.8291015625 spend 75.00508284568787 sec\n",
      "pose loss:-0.07646294683218002 conf loss:-0.12442941218614578 generate loss:-2125.45263671875 spend 71.47250151634216 sec\n",
      "pose loss:0.10342272371053696 conf loss:0.06662426888942719 generate loss:-1467.4090576171875 spend 73.18290495872498 sec\n",
      "pose loss:-0.07612008601427078 conf loss:-0.1381511241197586 generate loss:-2066.77685546875 spend 72.59848809242249 sec\n",
      "pose loss:-0.5104604363441467 conf loss:-0.48560184240341187 generate loss:-1962.967041015625 spend 71.84692287445068 sec\n",
      "pose loss:-0.4819815754890442 conf loss:-0.4648948907852173 generate loss:-2054.77783203125 spend 71.79694747924805 sec\n",
      "pose loss:0.06411319226026535 conf loss:0.0674583837389946 generate loss:-1704.711181640625 spend 71.87794327735901 sec\n",
      "pose loss:0.0014203153550624847 conf loss:-0.003528075758367777 generate loss:-1838.572021484375 spend 71.66282773017883 sec\n",
      "pose loss:0.05251893401145935 conf loss:0.05094475671648979 generate loss:-1652.5906982421875 spend 78.28816676139832 sec\n",
      "pose loss:0.04779274761676788 conf loss:0.04772593080997467 generate loss:-1790.754150390625 spend 72.99172353744507 sec\n",
      "pose loss:0.07620017230510712 conf loss:0.0657329112291336 generate loss:-1511.22607421875 spend 75.76556658744812 sec\n",
      "pose loss:0.029535092413425446 conf loss:0.028338966891169548 generate loss:-1964.402587890625 spend 86.33862972259521 sec\n",
      "pose loss:0.07730867713689804 conf loss:0.05698390305042267 generate loss:-1516.3175048828125 spend 133.87651109695435 sec\n",
      "pose loss:0.04949752986431122 conf loss:0.036218781024217606 generate loss:-1557.9088134765625 spend 114.22289299964905 sec\n",
      "pose loss:-0.03505583107471466 conf loss:-0.039019644260406494 generate loss:-1715.0050048828125 spend 85.92563581466675 sec\n",
      "pose loss:-0.1619272381067276 conf loss:-0.16069631278514862 generate loss:-1966.914794921875 spend 71.66483473777771 sec\n",
      "pose loss:0.04995635896921158 conf loss:0.048153556883335114 generate loss:-1534.8433837890625 spend 72.28255105018616 sec\n",
      "pose loss:0.022585418075323105 conf loss:0.025407878682017326 generate loss:-1656.0626220703125 spend 73.22503542900085 sec\n",
      "pose loss:0.025692496448755264 conf loss:0.03289268910884857 generate loss:-1588.5052490234375 spend 72.02008485794067 sec\n",
      "pose loss:0.06041502207517624 conf loss:0.03457489237189293 generate loss:-1640.833984375 spend 73.67114043235779 sec\n",
      "pose loss:0.06578630208969116 conf loss:0.03961171582341194 generate loss:-1560.3841552734375 spend 96.91001152992249 sec\n",
      "pose loss:-0.06666886806488037 conf loss:-0.0906156525015831 generate loss:-2117.8564453125 spend 107.30382418632507 sec\n",
      "pose loss:0.07423897087574005 conf loss:0.05970724672079086 generate loss:-1469.5814208984375 spend 102.6346046924591 sec\n",
      "pose loss:-0.07601436227560043 conf loss:-0.10925373435020447 generate loss:-2062.942626953125 spend 89.10363268852234 sec\n",
      "pose loss:-0.4107286036014557 conf loss:-0.3829587399959564 generate loss:-1935.179443359375 spend 75.57541084289551 sec\n",
      "pose loss:-0.3677186667919159 conf loss:-0.3454867899417877 generate loss:-2042.90380859375 spend 77.27066540718079 sec\n",
      "pose loss:0.03881755471229553 conf loss:0.0594148226082325 generate loss:-1703.313232421875 spend 67.66213202476501 sec\n",
      "pose loss:-0.01072625070810318 conf loss:-0.0048804692924022675 generate loss:-1836.8995361328125 spend 74.39962697029114 sec\n",
      "pose loss:0.03986416757106781 conf loss:0.04686608910560608 generate loss:-1646.407958984375 spend 76.17682003974915 sec\n",
      "pose loss:0.03217565640807152 conf loss:0.042476460337638855 generate loss:-1776.5472412109375 spend 84.86668729782104 sec\n",
      "pose loss:0.056863851845264435 conf loss:0.05819857120513916 generate loss:-1522.59619140625 spend 78.98968839645386 sec\n",
      "pose loss:0.02271421067416668 conf loss:0.026293892413377762 generate loss:-1929.855224609375 spend 73.68014717102051 sec\n",
      "pose loss:0.0810708999633789 conf loss:0.05094236880540848 generate loss:-1546.3544921875 spend 118.54224443435669 sec\n",
      "pose loss:0.05205916613340378 conf loss:0.03229084610939026 generate loss:-1530.6923828125 spend 82.83764815330505 sec\n",
      "pose loss:-0.03391216695308685 conf loss:-0.028266465291380882 generate loss:-1721.6546630859375 spend 80.89395904541016 sec\n",
      "pose loss:-0.14474694430828094 conf loss:-0.129037544131279 generate loss:-1945.571044921875 spend 80.21850800514221 sec\n",
      "pose loss:0.0364387109875679 conf loss:0.04184768348932266 generate loss:-1546.728759765625 spend 75.7205080986023 sec\n",
      "pose loss:0.014334090054035187 conf loss:0.02242588996887207 generate loss:-1639.3685302734375 spend 77.73997187614441 sec\n",
      "pose loss:0.016155598685145378 conf loss:0.03187193349003792 generate loss:-1586.7249755859375 spend 79.96136617660522 sec\n",
      "pose loss:0.045905567705631256 conf loss:0.03088867850601673 generate loss:-1642.715087890625 spend 77.20696806907654 sec\n",
      "pose loss:0.053108759224414825 conf loss:0.033377837389707565 generate loss:-1542.577392578125 spend 72.55845308303833 sec\n",
      "pose loss:-0.06158819794654846 conf loss:-0.06985500454902649 generate loss:-2106.298583984375 spend 71.84500169754028 sec\n",
      "pose loss:0.04966616630554199 conf loss:0.05168220400810242 generate loss:-1468.7110595703125 spend 70.89528918266296 sec\n",
      "pose loss:-0.07786910980939865 conf loss:-0.0901620090007782 generate loss:-2046.004150390625 spend 76.77029538154602 sec\n",
      "pose loss:-0.3400724530220032 conf loss:-0.30917873978614807 generate loss:-1914.8414306640625 spend 93.57915377616882 sec\n",
      "pose loss:-0.2926511764526367 conf loss:-0.26638779044151306 generate loss:-2034.488037109375 spend 78.32748770713806 sec\n",
      "pose loss:0.01595066487789154 conf loss:0.050710711628198624 generate loss:-1699.3084716796875 spend 77.51084017753601 sec\n",
      "pose loss:-0.02153528854250908 conf loss:-0.007231662515550852 generate loss:-1830.4521484375 spend 79.45502614974976 sec\n",
      "pose loss:0.02673686109483242 conf loss:0.041257139295339584 generate loss:-1636.964599609375 spend 79.00289869308472 sec\n",
      "pose loss:0.016201552003622055 conf loss:0.03612840175628662 generate loss:-1758.8994140625 spend 160.37797737121582 sec\n",
      "pose loss:0.040044914931058884 conf loss:0.04942205920815468 generate loss:-1527.458251953125 spend 78.35326385498047 sec\n",
      "pose loss:0.018506906926631927 conf loss:0.022075124084949493 generate loss:-1888.9854736328125 spend 72.5894193649292 sec\n",
      "pose loss:0.09195902943611145 conf loss:0.04429297149181366 generate loss:-1571.610595703125 spend 73.38695120811462 sec\n",
      "pose loss:0.06319674104452133 conf loss:0.02736531011760235 generate loss:-1497.13330078125 spend 73.44498944282532 sec\n",
      "pose loss:-0.029544763267040253 conf loss:-0.02206289768218994 generate loss:-1732.12353515625 spend 91.22785210609436 sec\n",
      "pose loss:-0.1312611699104309 conf loss:-0.10779585689306259 generate loss:-1915.3189697265625 spend 88.65913844108582 sec\n",
      "pose loss:0.027192136272788048 conf loss:0.03502093255519867 generate loss:-1558.8916015625 spend 78.74452447891235 sec\n",
      "pose loss:0.008782435208559036 conf loss:0.017682217061519623 generate loss:-1613.2000732421875 spend 74.62978053092957 sec\n",
      "pose loss:0.005832120776176453 conf loss:0.027499083429574966 generate loss:-1584.621337890625 spend 73.95032691955566 sec\n",
      "pose loss:0.029802758246660233 conf loss:0.02555479295551777 generate loss:-1631.9219970703125 spend 76.26386976242065 sec\n",
      "pose loss:0.035703144967556 conf loss:0.025855809450149536 generate loss:-1527.3941650390625 spend 80.30956840515137 sec\n",
      "pose loss:-0.06311653554439545 conf loss:-0.057218585163354874 generate loss:-2086.55517578125 spend 76.5030300617218 sec\n",
      "pose loss:0.02575952745974064 conf loss:0.04247642681002617 generate loss:-1470.5322265625 spend 75.1083734035492 sec\n",
      "pose loss:-0.08232085406780243 conf loss:-0.07786369323730469 generate loss:-2017.968994140625 spend 105.55933690071106 sec\n",
      "pose loss:-0.28969714045524597 conf loss:-0.25464245676994324 generate loss:-1906.717041015625 spend 90.98232316970825 sec\n",
      "pose loss:-0.24155446887016296 conf loss:-0.2124985307455063 generate loss:-2018.1964111328125 spend 82.37427568435669 sec\n",
      "pose loss:-0.008449768647551537 conf loss:0.0406641885638237 generate loss:-1688.154296875 spend 74.09542298316956 sec\n",
      "pose loss:-0.03287964314222336 conf loss:-0.011576222255825996 generate loss:-1813.7626953125 spend 75.1221079826355 sec\n",
      "pose loss:0.012356877326965332 conf loss:0.034471772611141205 generate loss:-1621.22021484375 spend 74.63278222084045 sec\n",
      "pose loss:-0.0015194173902273178 conf loss:0.027750074863433838 generate loss:-1735.275390625 spend 72.44832491874695 sec\n",
      "pose loss:0.023445412516593933 conf loss:0.039819564670324326 generate loss:-1526.532958984375 spend 77.54572558403015 sec\n",
      "pose loss:0.014217853546142578 conf loss:0.016640683636069298 generate loss:-1846.460205078125 spend 77.46667146682739 sec\n",
      "pose loss:0.1030779778957367 conf loss:0.03643658384680748 generate loss:-1582.9847412109375 spend 74.57474303245544 sec\n",
      "pose loss:0.07271690666675568 conf loss:0.0222154688090086 generate loss:-1463.59619140625 spend 80.53571844100952 sec\n",
      "pose loss:-0.02704942226409912 conf loss:-0.01962992735207081 generate loss:-1728.58154296875 spend 84.51837468147278 sec\n",
      "pose loss:-0.12287439405918121 conf loss:-0.09448641538619995 generate loss:-1884.33349609375 spend 102.73456931114197 sec\n",
      "pose loss:0.017613254487514496 conf loss:0.02696985751390457 generate loss:-1556.9364013671875 spend 115.396324634552 sec\n",
      "pose loss:0.0023263730108737946 conf loss:0.012079212814569473 generate loss:-1585.1812744140625 spend 82.38721776008606 sec\n",
      "pose loss:-0.006510522216558456 conf loss:0.020549826323986053 generate loss:-1573.9268798828125 spend 76.78663110733032 sec\n",
      "pose loss:0.012940019369125366 conf loss:0.018985824659466743 generate loss:-1610.071533203125 spend 72.71758365631104 sec\n",
      "pose loss:0.014391854405403137 conf loss:0.01648676209151745 generate loss:-1514.846435546875 spend 76.57910704612732 sec\n",
      "pose loss:-0.0693027451634407 conf loss:-0.050223466008901596 generate loss:-2055.79345703125 spend 75.20050263404846 sec\n",
      "pose loss:0.0019359514117240906 conf loss:0.03227180987596512 generate loss:-1463.0853271484375 spend 75.26022171974182 sec\n",
      "pose loss:-0.08775515109300613 conf loss:-0.07182295620441437 generate loss:-1982.8712158203125 spend 87.83271288871765 sec\n",
      "pose loss:-0.2535572350025177 conf loss:-0.21467570960521698 generate loss:-1890.770751953125 spend 82.51445412635803 sec\n",
      "pose loss:-0.20703361928462982 conf loss:-0.17486722767353058 generate loss:-1987.94384765625 spend 77.81496047973633 sec\n",
      "pose loss:-0.03462167829275131 conf loss:0.028802085667848587 generate loss:-1673.497802734375 spend 75.17314291000366 sec\n",
      "pose loss:-0.04678508639335632 conf loss:-0.016687732189893723 generate loss:-1784.84326171875 spend 74.86493730545044 sec\n",
      "pose loss:-0.00472477450966835 conf loss:0.026049060747027397 generate loss:-1601.374267578125 spend 75.90463018417358 sec\n",
      "pose loss:-0.02165621519088745 conf loss:0.01773076318204403 generate loss:-1704.974853515625 spend 75.97379350662231 sec\n",
      "pose loss:0.004937123507261276 conf loss:0.028603658080101013 generate loss:-1513.89306640625 spend 76.79024887084961 sec\n",
      "pose loss:0.005283549427986145 conf loss:0.008245176635682583 generate loss:-1807.8128662109375 spend 98.71956276893616 sec\n",
      "pose loss:0.10099517554044724 conf loss:0.02732098288834095 generate loss:-1566.5162353515625 spend 81.52651262283325 sec\n",
      "pose loss:0.06212720274925232 conf loss:0.015547244809567928 generate loss:-1439.0462646484375 spend 76.00869989395142 sec\n",
      "pose loss:-0.03741121292114258 conf loss:-0.021395456045866013 generate loss:-1701.763427734375 spend 74.32257556915283 sec\n",
      "pose loss:-0.12458250671625137 conf loss:-0.08757448196411133 generate loss:-1854.591552734375 spend 77.6958258152008 sec\n",
      "pose loss:0.0026804134249687195 conf loss:0.017281224951148033 generate loss:-1535.791015625 spend 79.66814088821411 sec\n",
      "pose loss:-0.009627006947994232 conf loss:0.004466052167117596 generate loss:-1558.040283203125 spend 112.67075610160828 sec\n",
      "pose loss:-0.02277054265141487 conf loss:0.011346330866217613 generate loss:-1547.1092529296875 spend 78.31727385520935 sec\n",
      "pose loss:-0.004164498299360275 conf loss:0.010893702507019043 generate loss:-1577.5047607421875 spend 81.91172051429749 sec\n",
      "pose loss:-0.008462999016046524 conf loss:0.005342680029571056 generate loss:-1495.452392578125 spend 78.76866436004639 sec\n",
      "pose loss:-0.07893142104148865 conf loss:-0.048667293041944504 generate loss:-2013.3082275390625 spend 82.02787756919861 sec\n",
      "pose loss:-0.022036084905266762 conf loss:0.019924061372876167 generate loss:-1446.5667724609375 spend 83.50002002716064 sec\n",
      "pose loss:-0.09479120373725891 conf loss:-0.0701340064406395 generate loss:-1938.18505859375 spend 78.23281574249268 sec\n",
      "pose loss:-0.22986137866973877 conf loss:-0.1865040808916092 generate loss:-1868.868896484375 spend 77.69384551048279 sec\n",
      "pose loss:-0.1856928914785385 conf loss:-0.14987902343273163 generate loss:-1947.4046630859375 spend 76.52704548835754 sec\n",
      "pose loss:-0.06355289369821548 conf loss:0.014438195154070854 generate loss:-1646.697509765625 spend 85.27688145637512 sec\n",
      "pose loss:-0.061843354254961014 conf loss:-0.02429836243391037 generate loss:-1746.187744140625 spend 84.59242606163025 sec\n",
      "pose loss:-0.02506248652935028 conf loss:0.014995929785072803 generate loss:-1565.5789794921875 spend 75.8535966873169 sec\n",
      "pose loss:-0.04624812677502632 conf loss:0.004716845694929361 generate loss:-1668.6273193359375 spend 73.99936008453369 sec\n",
      "pose loss:-0.018788740038871765 conf loss:0.015107229351997375 generate loss:-1481.913818359375 spend 73.20583009719849 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-ad742e875420>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0md_pose_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mD_pose_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD_pose_solver\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0md_conf_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mD_conf_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD_conf_solver\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mg_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mG_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG_solver\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[0mspend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbegin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0msummary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    fileWriter = tf.summary.FileWriter(\"summary\", sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    count = 1\n",
    "    for epoch in range(epoches):\n",
    "        for i, (each_batch, pose_heatmap, occlusion_heatmap) in enumerate(preprocessor.get_batch()):\n",
    "            #print(each_batch.shape, pose_heatmap.shape, occlusion_heatmap.shape)\n",
    "\n",
    "            feed_dict={\n",
    "                    generator.inputs:each_batch,\n",
    "                    pose_pl:pose_heatmap,\n",
    "                    occlusion_pl:occlusion_heatmap\n",
    "                }\n",
    "            begin = time.time()\n",
    "            d_pose_loss, _ = sess.run([D_pose_loss, D_pose_solver], feed_dict=feed_dict)\n",
    "            d_conf_loss, _ = sess.run([D_conf_loss, D_conf_solver], feed_dict=feed_dict)\n",
    "            g_loss, _ = sess.run([G_loss, G_solver], feed_dict=feed_dict)\n",
    "            spend = time.time() - begin\n",
    "            summary = sess.run(merged, feed_dict=feed_dict)\n",
    "            print(\"pose loss:{}\".format(d_pose_loss),\n",
    "                 \"conf loss:{}\".format(d_conf_loss),\n",
    "                 \"generate loss:{}\".format(g_loss),\n",
    "                 \"spend {} sec\".format(spend))\n",
    "            fileWriter.add_summary(summary, i+1)\n",
    "    saver.save(sess, \"save/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
